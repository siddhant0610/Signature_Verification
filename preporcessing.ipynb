{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd05b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kashi\\onedrive\\desktop\\github_ml\\sig\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\kashi\\onedrive\\desktop\\github_ml\\sig\\lib\\site-packages (from opencv-python) (2.2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88445fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop_to_signature(gray, thresh_val=220):\n",
    "    \"\"\"\n",
    "    Crop the image to the bounding box of the signature ink.\n",
    "    Assumes light background, dark strokes.\n",
    "    \"\"\"\n",
    "    # Binary image: background white(255), signature black(0) after inversion\n",
    "    _, th = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Find all non-zero points (signature area)\n",
    "    coords = cv2.findNonZero(th)\n",
    "    if coords is None:\n",
    "        # No ink detected, return original\n",
    "        return gray\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    cropped = gray[y:y+h, x:x+w]\n",
    "    return cropped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f333994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deskew(gray):\n",
    "    \"\"\"\n",
    "    Deskew the signature using image moments.\n",
    "    Works best when background is clean and signature is main object.\n",
    "    \"\"\"\n",
    "    # Threshold to isolate signature\n",
    "    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    coords = np.column_stack(np.where(th > 0))\n",
    "    if coords.size == 0:\n",
    "        return gray\n",
    "    \n",
    "    # Fit a min-area rectangle around the ink\n",
    "    rect = cv2.minAreaRect(coords.astype(np.float32))\n",
    "    angle = rect[-1]\n",
    "    \n",
    "    # Correct OpenCV's angle convention\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    \n",
    "    # Small angles not worth rotating\n",
    "    if abs(angle) < 1:\n",
    "        return gray\n",
    "    \n",
    "    (h, w) = gray.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(gray, M, (w, h),\n",
    "                             flags=cv2.INTER_CUBIC,\n",
    "                             borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7aed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_signature(\n",
    "    img_input,\n",
    "    size=224,\n",
    "    mean=0.5,\n",
    "    std=0.5,\n",
    "    deskew=True,\n",
    "    crop=True,\n",
    "    as_tensor=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Best-practice preprocessing for signature images.\n",
    "    \n",
    "    Args:\n",
    "        img_input: str path OR numpy array (BGR or grayscale).\n",
    "        size: final output size (size x size).\n",
    "        mean, std: normalization params for model input (after 0-1 scaling).\n",
    "        deskew: whether to attempt deskewing the signature.\n",
    "        crop: whether to crop to the tight bounding box around the signature.\n",
    "        as_tensor: if True, output shape is (1, H, W) for CNN input.\n",
    "        \n",
    "    Returns:\n",
    "        img_norm: float32 array in shape (H, W) or (1, H, W),\n",
    "                  normalized and ready for model.\n",
    "    \"\"\"\n",
    "    # 1. Load image as grayscale\n",
    "    if isinstance(img_input, str):\n",
    "        gray = cv2.imread(img_input, cv2.IMREAD_GRAYSCALE)\n",
    "        if gray is None:\n",
    "            raise ValueError(f\"Could not read image from path: {img_input}\")\n",
    "    else:\n",
    "        img = img_input\n",
    "        # If BGR, convert to grayscale\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        elif len(img.shape) == 3 and img.shape[2] == 1:\n",
    "            gray = img[:, :, 0]\n",
    "        else:\n",
    "            gray = img.copy()\n",
    "\n",
    "    # 2. Slight blur to reduce sensor/paper noise (very light)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # 3. Optional crop to signature content\n",
    "    if crop:\n",
    "        gray = _crop_to_signature(gray)\n",
    "\n",
    "    # 4. Optional deskew\n",
    "    if deskew:\n",
    "        gray = _deskew(gray)\n",
    "\n",
    "    # 5. Resize with aspect ratio preserved + pad to square\n",
    "    h, w = gray.shape\n",
    "    if h == 0 or w == 0:\n",
    "        raise ValueError(\"Empty image encountered after cropping/deskewing.\")\n",
    "\n",
    "    scale = size / max(h, w)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    h2, w2 = resized.shape\n",
    "    pad_top = (size - h2) // 2\n",
    "    pad_bottom = size - h2 - pad_top\n",
    "    pad_left = (size - w2) // 2\n",
    "    pad_right = size - w2 - pad_left\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        resized,\n",
    "        pad_top, pad_bottom, pad_left, pad_right,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=255  # white background\n",
    "    )\n",
    "\n",
    "    # 6. Convert to float and scale to [0, 1]\n",
    "    img_float = padded.astype(np.float32) / 255.0\n",
    "\n",
    "    # 7. Normalize with mean/std (like standard CNN input)\n",
    "    # Result is roughly in range [-1, 1] if mean=0.5, std=0.5\n",
    "    img_norm = (img_float - mean) / std\n",
    "\n",
    "    # 8. Add channel dimension if using with CNNs (C, H, W)\n",
    "    if as_tensor:\n",
    "        img_norm = np.expand_dims(img_norm, axis=0)\n",
    "\n",
    "    return img_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7375cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = preprocess_signature(\"sig1.jpg\")\n",
    "cv2.imwrite(\"processed_sig1.png\", processed[0]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f8f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
